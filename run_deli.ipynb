{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from model.booster import GBDT_Muti\n",
    "from model.dataset import DataSet\n",
    "from model.configs import Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv(\"data/Delicious/Delicious_data.txt\", sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = dt[0][0].split(\" \")\n",
    "N = int(info[0]) # Num_Points\n",
    "D = int(info[1]) # Num_Features\n",
    "L = int(info[2]) # Num_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dt.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>77,91,315,544,575,621,718,818,819,834,908 60:1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>82,99,205,357,365,386,387,395,396,398,470,625,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>76,332,333,453,552,799 6:1.000000 7:1.000000 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>332,333,339,353,456,507,573,574,615,731,783,78...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>77,104,108,205,223,275,276,285,286,296,378,381...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "1  77,91,315,544,575,621,718,818,819,834,908 60:1...\n",
       "2  82,99,205,357,365,386,387,395,396,398,470,625,...\n",
       "3  76,332,333,453,552,799 6:1.000000 7:1.000000 1...\n",
       "4  332,333,339,353,456,507,573,574,615,731,783,78...\n",
       "5  77,104,108,205,223,275,276,285,286,296,378,381..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16105/16105 [00:01<00:00, 15391.54it/s]\n"
     ]
    }
   ],
   "source": [
    "labels_onehot = []\n",
    "features_onehot = []\n",
    "for thing in tqdm(dt[0]):\n",
    "    thing = str(thing)\n",
    "    all_thing = thing.split(\" \",1)\n",
    "    labels = all_thing[0].split(\",\")\n",
    "    try:\n",
    "        labels = [int(i) for i in labels]\n",
    "    except:\n",
    "        labels = []\n",
    "    features = all_thing[1].split(\" \")\n",
    "    features = {int(i.split(':')[0]):float(i.split(':')[1]) for i in features}\n",
    "    label_onehot = [0]*L\n",
    "    feature_onehot = [0.0]*D\n",
    "    for i in labels:\n",
    "        label_onehot[i] = 1\n",
    "    for i in features:\n",
    "        feature_onehot[i] = features[i]\n",
    "    labels_onehot.append(label_onehot)\n",
    "    features_onehot.append(feature_onehot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=100)\n",
    "features_onehot = pca.fit_transform(features_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(features_onehot), np.array(labels_onehot), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12884, 983)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12884, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = DataSet(x_train, y_train)\n",
    "dataset_test = DataSet(x_test, y_test)\n",
    "configs = Configs('configs/configs_delicious.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter1 : valid loss=18.966160\n",
      "iter1 : train loss=17.103588\n",
      "iter2 : valid loss=17.190654\n",
      "iter2 : train loss=16.468521\n",
      "iter3 : valid loss=16.673671\n",
      "iter3 : train loss=16.149860\n",
      "iter4 : valid loss=16.455227\n",
      "iter4 : train loss=15.944632\n",
      "iter5 : valid loss=16.335535\n",
      "iter5 : train loss=15.767733\n",
      "iter6 : valid loss=16.259470\n",
      "iter6 : train loss=15.650057\n",
      "iter7 : valid loss=16.215842\n",
      "iter7 : train loss=15.542323\n",
      "iter8 : valid loss=16.188664\n",
      "iter8 : train loss=15.464611\n",
      "iter9 : valid loss=16.160058\n",
      "iter9 : train loss=15.405812\n",
      "iter10 : valid loss=16.148877\n",
      "iter10 : train loss=15.351508\n",
      "iter11 : valid loss=16.138807\n",
      "iter11 : train loss=15.345163\n",
      "iter12 : valid loss=16.132874\n",
      "iter12 : train loss=15.288275\n",
      "iter13 : valid loss=16.129685\n",
      "iter13 : train loss=15.240553\n",
      "iter14 : valid loss=16.122815\n",
      "iter14 : train loss=15.236802\n",
      "iter15 : valid loss=16.119557\n",
      "iter15 : train loss=15.202321\n",
      "iter16 : valid loss=16.115647\n",
      "iter16 : train loss=15.199449\n",
      "iter17 : valid loss=16.112963\n",
      "iter17 : train loss=15.197095\n",
      "iter18 : valid loss=16.110520\n",
      "iter18 : train loss=15.195045\n",
      "iter19 : valid loss=16.108244\n",
      "iter19 : train loss=15.193232\n",
      "iter20 : valid loss=16.106650\n",
      "iter20 : train loss=15.191570\n",
      "iter21 : valid loss=16.105143\n",
      "iter21 : train loss=15.189925\n",
      "iter22 : valid loss=16.103657\n",
      "iter22 : train loss=15.188481\n",
      "iter23 : valid loss=16.102112\n",
      "iter23 : train loss=15.154631\n",
      "iter24 : valid loss=16.104633\n",
      "Early stop at iter 24\n"
     ]
    }
   ],
   "source": [
    "gbdt = GBDT_Muti(configs)\n",
    "gbdt.fit(dataset_train,dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = gbdt.predict_set_prob(dataset_test.X)\n",
    "pred_labels = gbdt.predict_set_label(dataset_test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_df = pd.DataFrame(pred_prob)\n",
    "pred_labels_df = pd.DataFrame(pred_labels)\n",
    "pred_prob_df.to_csv('./result/deli_pred_prob.csv', index=False)\n",
    "pred_labels_df.to_csv('./result/deli_pred_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02674511895961375"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_macro = f1_score(y_test, pred_labels_df, average='macro')\n",
    "f1_score_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1375949590719039"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_micro = f1_score(y_test, pred_labels_df, average='micro')\n",
    "f1_score_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0027941633033219497"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, pred_labels_df)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01850079100056439"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham = hamming_loss(y_test, pred_labels_df)\n",
    "ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = pd.read_csv('record.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Delicious'\n",
    "record = record.append([{\n",
    "    \"dataset\": dataset_name,\n",
    "    \"learn_rate\": configs.learn_rate,\n",
    "    \"max_depth\": configs.max_depth,\n",
    "    \"stop_iter\": gbdt.stop_iter,\n",
    "    \"f1_score_macro\":f1_score_macro,\n",
    "    \"f1_score_micro\":f1_score_micro,\n",
    "    \"acc\":acc,\n",
    "    \"ham\":ham\n",
    "    }])\n",
    "record.to_csv('record.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_top_k(pred_prob, top_k=1, reverse=False):\n",
    "    \"\"\" pred_prob: [N*L]@ndarray \"\"\"\n",
    "    top_k_idx = np.argsort(pred_prob, axis=1)\n",
    "    if reverse:\n",
    "        return top_k_idx[:, -top_k:]\n",
    "    else:\n",
    "        return top_k_idx[:, :top_k]\n",
    "\n",
    "def precision_at_k(pred_prob, pred_label, targets, k):\n",
    "    \"\"\" All array is [N*L]@ndarray \"\"\"\n",
    "    assert k>=1 and k <= np.size(targets, 1)\n",
    "    topkidx = get_sorted_top_k(pred_prob, top_k=k, reverse=True)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for j in range(k):\n",
    "        for i in range(len(pred_prob)):      # 取每个样本\n",
    "            jth_idx = topkidx[i, j]\n",
    "            if pred_label[i, jth_idx] > 0:   # 预测为正例\n",
    "                if targets[i, jth_idx] > 0:  # 真实为正例\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "    p_at_k = tp / (tp + fp)\n",
    "    return p_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7048755186721992"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_k(pred_prob, pred_labels, y_test, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6986839067190025"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_k(pred_prob, pred_labels, y_test, k=3)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdff712494efa4aeb3315a17d78016ed4c255fc3d660f39cd520f95c61be32e4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
